//! This example is used by a python module for benchmarking airs. It offers a CLI to control its
//! behavior and measures time itself to make it easier to exclude parsing times for data.

use std::fs::{read, File};
use std::io;
use std::io::Write;
use std::path::{Path, PathBuf};
use std::process::exit;
use std::time::{Duration, Instant};

use clap::{Args, Parser, Subcommand, ValueEnum};
use serde::Serialize;

use libairs::ancestors::{AncestorArray, AncestorGenerator};
use libairs::ts::ViterbiMatcher;
use libairs::variants::{VariantData, VariantDataBuilder};

#[derive(Parser)]
#[command(version, arg_required_else_help = true)]
struct CliArgs {
    #[arg(short = 't', long = "threads", default_value_t = 1)]
    num_threads: u16,

    #[command(subcommand)]
    command: Action,
}

#[derive(Subcommand)]
enum Action {
    GenerateAncestors {
        #[command(flatten)]
        data_source: Input,

        /// The length of the DNA sequence, since not all VCF files contain this information
        #[arg(short, long)]
        sequence_length: usize,

        /// Output path for the .aa file. Optional. Will default to the input path and just change
        /// the file extension.
        #[arg(short, long)]
        output: Option<String>,
    },
    MatchAncestors {
        /// A .aa file generated by a previous call to `generate-ancestors`
        #[arg(short, long)]
        ancestors: String,

        /// Output path for the .aa file. Optional. Will default to the input path and just change
        /// the file extension.
        #[arg(short, long)]
        output: Option<String>,
    },
    MatchSamples {},
    Infer {
        #[command(flatten)]
        data_source: Input,

        /// The length of the DNA sequence, since not all VCF files contain this information
        #[arg(short, long)]
        sequence_length: usize,
    },
}

#[derive(Args)]
#[group(required = true)]
struct Input {
    /// The type of input data
    #[arg(long = "type", value_enum)]
    input_type: InputType,

    /// The path to the input data
    #[arg(short = 'i', long)]
    path: String,

    /// Whether the input data is compressed (optional, default: no)
    #[arg(long, default_value_t = false)]
    compressed: bool,
}

#[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, ValueEnum)]
enum InputType {
    /// Import from a VCF file (proprietary vcf subset)
    Vcf,

    /// Import from a file containing sample data directly printed by a python script
    Python,
}

fn main() {
    let args = CliArgs::parse();

    if args.num_threads > 1 {
        rayon::ThreadPoolBuilder::new()
            .num_threads(args.num_threads as usize)
            .build_global()
            .unwrap();
    }

    match args.command {
        Action::GenerateAncestors {
            data_source,
            sequence_length,
            output,
        } => {
            let input_path = data_source.path.clone();

            let ag = parse_input(data_source, sequence_length).unwrap_or_else(|error| {
                eprintln!("could not parse input data: {}", error);
                exit(-1);
            });

            let start = Instant::now();
            let ancestors = ag.generate_ancestors();
            let end = start.elapsed();
            println!("generated {} ancestors in {:?}", ancestors.len(), end);

            write_output(&input_path, "aa", output, &ancestors);
        }
        Action::MatchAncestors { ancestors, output } => {
            let data = File::open(&ancestors).unwrap_or_else(|error| {
                eprintln!("could not read input file: {}", error);
                exit(-1);
            });
            let ancestor_array: AncestorArray =
                rmp_serde::from_read(&data).unwrap_or_else(|error| {
                    eprintln!("could not deserialize ancestors: {}", error);
                    exit(-1);
                });

            let start = Instant::now();
            let mut ancestor_matcher = ViterbiMatcher::new(ancestor_array, 1e-2, 1e-20, true, 40);
            ancestor_matcher.match_ancestors();
            let end = start.elapsed();
            println!("matched ancestors in {:?}", end);

            write_output(
                &ancestors,
                "pts",
                output,
                ancestor_matcher.get_partial_tree_sequence(),
            );
        }
        Action::MatchSamples { .. } => {}
        Action::Infer {
            data_source,
            sequence_length,
        } => {
            let ag = parse_input(data_source, sequence_length).unwrap_or_else(|error| {
                eprintln!("could not parse input data: {}", error);
                exit(-1);
            });

            let mut total = Duration::new(0, 0);

            let start = Instant::now();
            let ancestors = ag.generate_ancestors();
            let end = start.elapsed();
            total += end;
            println!("generated {} ancestors in {:?}", ancestors.len(), end);

            let start = Instant::now();
            let mut ancestor_matcher =
                libairs::ts::ViterbiMatcher::new(ancestors, 1e-2, 1e-20, true, 40);
            ancestor_matcher.match_ancestors();
            let end = start.elapsed();
            total += end;
            println!("matched ancestors in {:?}", end);

            let start = Instant::now();
            ancestor_matcher.match_samples();
            let end = start.elapsed();
            total += end;
            println!("matched samples in {:?}", end);

            println!("total time: {:?}", total);
        }
    }
}

fn parse_input(data_source: Input, sequence_length: usize) -> io::Result<AncestorGenerator> {
    match data_source.input_type {
        InputType::Vcf => libairs::convenience::from_vcf(
            &data_source.path,
            data_source.compressed,
            sequence_length,
        ),
        InputType::Python => import_python_data(&data_source.path, sequence_length),
    }
}

/// Write a serializable data structure to the optional output path or to the input path with the
/// provided extension.
fn write_output(
    input_path: &String,
    extension: &str,
    output: Option<String>,
    data: &impl Serialize,
) {
    let output_path = if let Some(path) = output {
        path
    } else {
        let mut buf = PathBuf::from(input_path);
        buf.set_extension(extension);
        String::from(buf.to_str().unwrap())
    };

    let serialized = rmp_serde::to_vec(&data).unwrap();
    File::create(output_path)
        .unwrap_or_else(|error| {
            eprintln!("could not create output file: {}", error);
            exit(-1);
        })
        .write_all(&serialized)
        .unwrap_or_else(|error| {
            eprintln!("could not write to output file: {}", error);
            exit(-1);
        });
}

/// Import a custom file with the following layout:
/// ```
/// num_samples
/// 0 1 0 1 repeat #num_samples... 0 position ancestral_state derived_state
/// repeat #num_variants often...
/// ```
// TODO wrap everything in errors instead of calling unwrap
fn import_python_data(path: &String, sequence_length: usize) -> io::Result<AncestorGenerator> {
    let data = std::fs::read_to_string(path)?;
    let mut lines = data.lines();
    let num_samples = lines.next().unwrap().parse::<usize>().unwrap();
    let mut builder = VariantDataBuilder::new(sequence_length);
    for line in lines {
        let mut parts = line.split_whitespace();
        let mut states = Vec::with_capacity(num_samples);
        for _ in 0..num_samples {
            states.push(parts.next().unwrap().parse::<u8>().unwrap());
        }
        let position = parts.next().unwrap().parse::<usize>().unwrap();
        let ancestral_state = parts.next().unwrap().chars().next().unwrap();
        let derived_state = parts.next().unwrap().chars().next().unwrap();
        builder.add_variant_site(states, position, ancestral_state, derived_state);
    }
    Ok(AncestorGenerator::from_variant_data(builder.finalize()))
}
