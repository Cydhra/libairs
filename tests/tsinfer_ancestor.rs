use libairs::ancestors::AncestorGenerator;
use libairs::dna::VariantSite;
use std::collections::HashMap;
use std::fs::File;
use std::io::{BufRead, BufReader};
use std::time::Instant;

/// Reads a specially formatted text file that contains data about variant sites intended for
/// unit testing. The data was generated by dumping it from tsinfer.
fn read_variant_dump(path: &str) -> impl Iterator<Item=VariantSite> {
    let input = File::open(path).expect("could not find test data");
    let reader = BufReader::new(input);
    reader.lines().enumerate().map(|(pos, line)| {
        VariantSite::new(
            line.expect("unexpected io error")
                .trim()
                .split(" ")
                .map(|s| s.parse().expect("corrupt input data"))
                .collect::<Vec<_>>(),
            pos,
        )
    })
}

/// Reads a specially formatted text file that contains data about ancestral sequences intended
/// for unit testing. The data was generated by dumping it from tsinfer.
fn read_ancestor_dump(path: &str) -> HashMap<Vec<usize>, Vec<u8>> {
    let input = File::open(path).expect("could not find test results");
    let reader = BufReader::new(input);
    let mut tsinfer_ancestors = HashMap::new();
    reader.lines().for_each(|line| {
        let line = line.expect("unexpected IO error");
        let mut line_parts = line.splitn(2, ": ");
        let first_part = line_parts.next();
        let index: Vec<usize> = first_part
            .expect("corrupted test results")
            .strip_prefix("[")
            .unwrap()
            .strip_suffix("]")
            .unwrap()
            .split(" ")
            .filter(|s| !s.is_empty())
            .map(|s| {
                s.parse()
                    .expect(&format!("corrupted focal sites: {}", first_part.expect("")))
            })
            .collect();
        tsinfer_ancestors.insert(
            index,
            line_parts
                .next()
                .expect("corrupted test results")
                .trim()
                .split(" ")
                .map(|bit| bit.parse().expect("corrupted test results"))
                .collect(),
        );
    });
    tsinfer_ancestors
}

#[test]
#[ignore]
fn compute_chr20_40_variants() {
    let variant_sites = read_variant_dump("testdata/chr20_40variants.txt");

    let ag = AncestorGenerator::from_iter(variant_sites);
    let ancestors = ag.generate_ancestors();

    let tsinfer_ancestors = read_ancestor_dump("testdata/chr20_40ancestors.txt");

    for (ancestor) in ancestors.iter() {
        assert_eq!(ancestor.focal_sites().len(), 1);
        for (pos, &state) in ancestor.haplotype().iter().enumerate() {
            assert_eq!(state, tsinfer_ancestors[ancestor.focal_sites()][pos]);
        }
    }
}

#[test]
#[ignore]
fn compute_chr20_10k_variants() {
    let variant_sites = read_variant_dump("testdata/chr20_10k_variants.txt");
    let ag = AncestorGenerator::from_iter(variant_sites);

    let start = Instant::now();
    let ancestors = ag.generate_ancestors();
    println!("10k variants processed in: {:?}", start.elapsed());
    assert_eq!(ancestors.len(), 5175);

    let tsinfer_ancestors = read_ancestor_dump("testdata/chr20_10k_ancestors.txt");

    for (index, ancestor) in ancestors.iter().enumerate() {
        assert!(
            ancestor.haplotype()
                .iter()
                .zip(tsinfer_ancestors[ancestor.focal_sites()].iter())
                .all(|(state, tsinfer_state)| { *state == *tsinfer_state }),
            "failed at index {} (bit {:?}), ancestor focal site: {:?}\nTSINFER:\t{:?}\n   AIRS:\t{:?}",
            index,
            ancestor.start() + ancestor.haplotype()
                .iter()
                .zip(tsinfer_ancestors[ancestor.focal_sites()].iter())
                .position(|(state, tsinfer_state)| { *state != *tsinfer_state }).unwrap(),
            ancestor.focal_sites(),
            tsinfer_ancestors[ancestor.focal_sites()],
            &ancestor.haplotype()
        );
    }
}
